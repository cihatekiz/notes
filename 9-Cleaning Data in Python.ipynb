{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ df.drop_duplicate()\n",
    "~ missing data  ==> leave as-is /drop them/fill missing values :.fillna() or using summary statistic :  median would make more sense if the data has outliers\n",
    "~ df['col1']= df['col1'].fillna(mean_value)\n",
    "~ TESTING WITH ASSERTS\n",
    "~ assert df.col1.notnull().all()  / assert df.col1.notnull().all()  ==>if no value returns which means the statement is true \n",
    "~ df.apply(func,axis=1 (for row wise ))\n",
    "~ pd.merge(df1,df2,df3)\n",
    "pd.concat([df1,df2,df3,df4])\n",
    "~ melt() --> to turn columns into rows\n",
    "~ pivot() --> will take unique values from a column and create new columns\n",
    "~ df.dtypes --- to_numeric / astype(str)\n",
    "~ df.to_csv('dasdas.csv')\n",
    "~ df.col=df.col.str.lower()\n",
    "~ df.col=df.col.str.upper()\n",
    "~ df.col=df.col.str.strip()\n",
    "~ pd.qcut(df['col_name'],q=3,labels=list) --> divides the data based on its distribution into the number of categories we set in the q argument. \n",
    "~ pd.cut(df[\"col_name\"],bins=ranges,labels=list)\n",
    "~# Create mapping dictionary and replacemapping = {'Microsoft':'DesktopOS', 'MacOS':'DesktopOS', 'Linux':'DesktopOS','IOS':'MobileOS', 'Android':'MobileOS'}devices['operating_system'] = devices['operating_system'].replace(mapping)devices['operating_system'].unique()array(['DesktopOS', 'MobileOS'], dtype=object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phones.loc[digits<10,\"phone number\"]=np.nan\n",
    "\n",
    "~ # Replace letters with nothing\n",
    "phones['Phone number'] = phones['Phone number'].str.replace(r'\\D+', '')phones.head()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.to_datetime()\n",
    "~pd.to_datetime(df['col_name'],infer_datetime_format=True,errors ='coerce')\n",
    "**CROSS FIELD VALIDATION**\n",
    "~the use of multiple field in a dataset to sanity check data integrity.\n",
    " \n",
    "~ users['birthday']=pd.to_datetime(users[\"birthday\"])\n",
    "~ today=dt.date.today()\n",
    "~ age_manual= today.year - users[\"birthday'].dt.year\n",
    "\n",
    "**COMPLETENESS**\n",
    "\n",
    "~technical error,human error\n",
    "~import missingno as msno  --> allows to create useful visualizations of our missing data.\n",
    " import matplotlib.pyplot as plt\n",
    " msno.matrix(airquality)\n",
    " plt.show()\n",
    "**MISSINGNESS TYPES**\n",
    "a) missing completely at random\n",
    "no systematic relationship between missing data\n",
    "and other values\n",
    "b) missing at random:\n",
    "systematic relationship between missing data and other observed values.\n",
    "c) missing not at random\n",
    "systematic relationship between missing data and unobserved values.\n",
    "\n",
    "**some approaches**\n",
    "-dropping missing data\n",
    "-impute with statistical measures\n",
    "-imputing using an algorithmic approach\n",
    "-impute with machine learning models\n",
    "\n",
    "df_new= df.dropna(subset=[\"CO2\"])\n",
    "**replacing with statistical measures**\n",
    "co2_mean = airquality['CO2'].mean()\n",
    "airquality_imputed = airquality.fillna({'CO2': co2_mean})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Strings / RECORD LINKAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**minimum edit distance** : a systematic wasy to identify how close 2 strings are.least possibel amount of steps needed to transiton from one str to another.\n",
    "**possible packages**: nltk,fuzzywuzzy,textdistance\n",
    "\n",
    "~from fuzzywuzzy import fuzz\n",
    "fuzz.WRatio('str1','str2')\n",
    "\n",
    "~from fuzzywuzzy import process\n",
    "\n",
    "process.extract(string,choices,limit=2)\n",
    "\n",
    "**Collapsing all of the state**\n",
    "\n",
    "for state in categories[\"state\"]:\n",
    "    # Find potential matches in states with typoes    \n",
    "    matches = process.extract(state, survey['state'], limit = survey.shape[0])\n",
    "    # For each potential match match\n",
    "    for potential_match in matches:\n",
    "    # If high similarity score\n",
    "        if potential_match[1] >= 80:\n",
    "        # Replace typo with correct category         \n",
    "        survey.loc[survey['state'] == potential_match[0], 'state'] = state\n",
    "\n",
    "~generating pairs:\n",
    "record linkage is the act of linking data from different sources regarding the same entity.\n",
    "\n",
    "~blocking : we apply to create pairs based on a matching column, reducing the number of possible pairs.\n",
    "\n",
    "import recordlinkage\n",
    "\n",
    "#create indexing object\n",
    "indexer= recordlinkage.Index()\n",
    "#generate pairs blocked on state\n",
    "indexer.block('state')\n",
    "pairs=indexer.index(census_A,census_B)\n",
    "#create a compare object \n",
    "compare_cl=recordlinkage.Compare()\n",
    "#find exact matches for pairs of date of birth and state\n",
    "\n",
    "compare_cl.exact('dateofbirth','dateofbirth',label='dateofbirth')\n",
    "compare_cl.string('surname', 'surname', threshold=0.85, label='surname')\n",
    " #Find matches\n",
    " potential_matches = compare_cl.compute(pairs, census_A, census_B)\n",
    "\n",
    "~LINKING DATAFRAMES~\n",
    "\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "#Get indices from census_B \n",
    "onlyduplicate_rows = matches.index.get_level_values(1)\n",
    "Finding duplicates in census_B\n",
    "census_B_duplicates = census_B[census_B.index.isin(duplicate_rows)]\n",
    "Finding new rows in census_B\n",
    "census_B_new = census_B[~census_B.index.isin(duplicate_rows)]\n",
    "#Link the DataFrames!\n",
    "full_census = census_A.append(census_B_new)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
